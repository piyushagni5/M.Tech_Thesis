{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Project-file-main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piyushagni5/M.Tech_project_file/blob/master/Project_file_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyRqh1QmZgw-",
        "colab_type": "code",
        "outputId": "70e85933-e39f-4f73-eb1a-4031ca4341ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip freeze\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "absl-py==0.9.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.1.0\n",
            "asgiref==3.2.7\n",
            "astor==0.8.1\n",
            "astropy==4.0.1.post1\n",
            "astunparse==1.6.3\n",
            "atari-py==0.2.6\n",
            "atomicwrites==1.4.0\n",
            "attrs==19.3.0\n",
            "audioread==2.1.8\n",
            "autograd==1.3\n",
            "Babel==2.8.0\n",
            "backcall==0.1.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.1.5\n",
            "blis==0.4.1\n",
            "bokeh==1.4.0\n",
            "boto==2.49.0\n",
            "boto3==1.13.4\n",
            "botocore==1.16.4\n",
            "Bottleneck==1.3.2\n",
            "branca==0.4.1\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cachetools==3.1.1\n",
            "catalogue==1.0.0\n",
            "certifi==2020.4.5.1\n",
            "cffi==1.14.0\n",
            "chainer==6.5.0\n",
            "chardet==3.0.4\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.4.0\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.2.0\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "csaps==0.11.0\n",
            "cufflinks==0.17.3\n",
            "cvxopt==1.2.5\n",
            "cvxpy==1.0.31\n",
            "cycler==0.10.0\n",
            "cymem==2.0.3\n",
            "Cython==0.29.17\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "dataclasses==0.7\n",
            "datascience==0.10.6\n",
            "decorator==4.4.2\n",
            "defusedxml==0.6.0\n",
            "descartes==1.1.0\n",
            "dill==0.3.1.1\n",
            "distributed==1.25.3\n",
            "Django==3.0.6\n",
            "dlib==19.18.0\n",
            "docopt==0.6.2\n",
            "docutils==0.15.2\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.221\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.2.5\n",
            "entrypoints==0.3\n",
            "ephem==3.7.7.1\n",
            "et-xmlfile==1.0.1\n",
            "fa2==0.3.5\n",
            "fancyimpute==0.4.3\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==0.2.3\n",
            "fastrlock==0.4\n",
            "fbprophet==0.6\n",
            "feather-format==0.4.1\n",
            "featuretools==0.4.1\n",
            "filelock==3.0.12\n",
            "firebase-admin==4.1.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.2\n",
            "folium==0.8.3\n",
            "fsspec==0.7.3\n",
            "future==0.16.0\n",
            "gast==0.3.3\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gin-config==0.3.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.16.0\n",
            "google-api-python-client==1.7.12\n",
            "google-auth==1.7.2\n",
            "google-auth-httplib2==0.0.3\n",
            "google-auth-oauthlib==0.4.1\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.6.2\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.51.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "grpcio==1.28.1\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.6\n",
            "gym==0.17.1\n",
            "h5py==2.10.0\n",
            "HeapDict==1.0.1\n",
            "holidays==0.9.12\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.3\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.9\n",
            "image==1.5.31\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==1.6.0\n",
            "imutils==0.5.3\n",
            "inflect==2.1.0\n",
            "intel-openmp==2020.0.133\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.5.1\n",
            "itsdangerous==1.1.0\n",
            "jax==0.1.64\n",
            "jaxlib==0.1.45\n",
            "jdcal==1.4.1\n",
            "jedi==0.17.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.2\n",
            "jmespath==0.9.5\n",
            "joblib==0.14.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.4\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.6.3\n",
            "kaggle==1.5.6\n",
            "kapre==0.1.3.1\n",
            "Keras==2.3.1\n",
            "Keras-Applications==1.0.8\n",
            "Keras-Preprocessing==1.1.0\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.2.0\n",
            "knnimpute==0.1.0\n",
            "librosa==0.6.3\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.31.0\n",
            "lmdb==0.98\n",
            "lucid==0.3.8\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.2.1\n",
            "MarkupSafe==1.1.1\n",
            "matplotlib==3.2.1\n",
            "matplotlib-venn==0.11.5\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.2.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.1.0\n",
            "msgpack==1.0.0\n",
            "multiprocess==0.70.9\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.2\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.0.6\n",
            "networkx==2.4\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.2.2\n",
            "np-utils==0.5.12.1\n",
            "numba==0.48.0\n",
            "numexpr==2.7.1\n",
            "numpy==1.18.4\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.0\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.2.1\n",
            "osqp==0.6.1\n",
            "packaging==20.3\n",
            "palettable==3.3.0\n",
            "pandas==1.0.3\n",
            "pandas-datareader==0.8.1\n",
            "pandas-gbq==0.11.0\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.2\n",
            "parso==0.7.0\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.0.0\n",
            "pip-tools==4.5.1\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "portpicker==1.3.1\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.2\n",
            "prettytable==0.7.2\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.7.1\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.10.0\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptvsd==5.0.0a12\n",
            "ptyprocess==0.6.0\n",
            "py==1.8.1\n",
            "pyarrow==0.14.1\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.0\n",
            "pycparser==2.20\n",
            "pydata-google-auth==1.1.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyglet==1.5.0\n",
            "Pygments==2.1.3\n",
            "pygobject==3.26.1\n",
            "pymc3==3.7\n",
            "PyMeeus==0.3.7\n",
            "pymongo==3.10.1\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.16.0\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==1.6.5+ubuntu0.2\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.1\n",
            "python-louvain==0.14\n",
            "python-slugify==4.0.0\n",
            "python-speech-features==0.6\n",
            "python-utils==2.4.0\n",
            "pytz==2018.9\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==19.0.1\n",
            "qtconsole==4.7.3\n",
            "QtPy==1.9.0\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.2.7\n",
            "rsa==4.0\n",
            "s3fs==0.4.2\n",
            "s3transfer==0.3.3\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.2.post1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.2\n",
            "seaborn==0.10.1\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.0\n",
            "simplegeneric==0.8.1\n",
            "six==1.12.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==2.0.0\n",
            "snowballstemmer==2.0.0\n",
            "sortedcontainers==2.1.0\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-websupport==1.2.2\n",
            "SQLAlchemy==1.3.16\n",
            "sqlparse==0.3.1\n",
            "srsly==1.0.2\n",
            "statsmodels==0.10.2\n",
            "sympy==1.1.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.7\n",
            "tbb==2020.0.133\n",
            "tblib==1.6.0\n",
            "tensorboard==2.2.1\n",
            "tensorboard-plugin-wit==1.6.0.post3\n",
            "tensorboardcolab==0.0.22\n",
            "tensorflow==2.2.0\n",
            "tensorflow-addons==0.8.3\n",
            "tensorflow-datasets==2.1.0\n",
            "tensorflow-estimator==2.2.0\n",
            "tensorflow-gcs-config==2.1.8\n",
            "tensorflow-hub==0.8.0\n",
            "tensorflow-metadata==0.21.2\n",
            "tensorflow-privacy==0.2.2\n",
            "tensorflow-probability==0.10.0rc0\n",
            "termcolor==1.1.0\n",
            "terminado==0.8.3\n",
            "testpath==0.4.4\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "textgenrnn==1.4.1\n",
            "Theano==1.0.4\n",
            "thinc==7.4.0\n",
            "toolz==0.10.0\n",
            "torch==1.5.0+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.6.0+cu101\n",
            "tornado==4.5.3\n",
            "tqdm==4.41.1\n",
            "traitlets==4.3.3\n",
            "tweepy==3.6.0\n",
            "typeguard==2.7.1\n",
            "typing==3.6.6\n",
            "typing-extensions==3.6.6\n",
            "tzlocal==1.5.1\n",
            "umap-learn==0.4.2\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.8.0\n",
            "wasabi==0.6.0\n",
            "wcwidth==0.1.9\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.15.1\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szq0Bz24bE1d",
        "colab_type": "code",
        "outputId": "3492fb64-1828-440f-99fa-6968ee29c512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFl8rW24XbQo",
        "colab_type": "code",
        "outputId": "d81cb8ce-c9c0-4c6b-fd23-8b131ecf46f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "!pip install csaps"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting csaps\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/fd/0698c6706a02c0002e73df5b713681497c5313a92b7df5b3d88a1c6dc1c6/csaps-0.11.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy<1.6.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from csaps) (1.4.1)\n",
            "Requirement already satisfied: numpy<1.20.0,>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from csaps) (1.18.4)\n",
            "Installing collected packages: csaps\n",
            "Successfully installed csaps-0.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgPwo5QIX9bc",
        "colab_type": "code",
        "outputId": "4d5ba727-7117-4271-f7dd-bcb68eca9de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "!pip install python_speech_features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5887 sha256=744bd7a89c7d8691931954016943a0f472d67c5d5db0f04d16729eaf4c26eec3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoGYB71SRbKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wave\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from scipy.io.wavfile import read\n",
        "import scipy\n",
        "\n",
        "from random import random\n",
        "import math\n",
        "from numpy.linalg import inv\n",
        "from scipy.linalg import toeplitz\n",
        "\n",
        "import wave, os, glob\n",
        "\n",
        "from scipy.interpolate import CubicSpline\n",
        "from scipy.interpolate import PchipInterpolator as pchip\n",
        "\n",
        "import librosa\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#from pycm import *\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import time\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "import csaps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQJSYeMKRbKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from python_speech_features import mfcc\n",
        "from python_speech_features import logfbank\n",
        "from python_speech_features.sigproc import preemphasis\n",
        "from python_speech_features.base import delta\n",
        "from python_speech_features.base import fbank\n",
        "from python_speech_features.sigproc import framesig\n",
        "\n",
        "from termcolor import colored"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyjmUIB1RbKX",
        "colab_type": "text"
      },
      "source": [
        "### EMODB DATASET DESCRIPTION\n",
        "\n",
        "1. 6 basics emotions- W-anger, L-boredom, E-disgust, A-anxiety, F-happiness, T-sadness, N-neutral\n",
        "\n",
        "2. 5F, 5M (10 utterences, 5 short & 5 longer)\n",
        "\n",
        "3. filename = 03a01Fa.wav --> 03-a01-F-a.wav\n",
        "              03--> speaker detail(M,31 year old) others are [08,09,10,11,12,13,14,15,16]\n",
        "              a01--> code for text\n",
        "              F--> emotion code\n",
        "              a--> if there are more than 2 versions (there are no. a,b,c...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id3bwzZMRbKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fixed points taken for spline interpolation\n",
        "xv=[0,0.35,0.69,1]    \n",
        "\n",
        "# FIXED PARAMETER FOR endSPLINE 2\n",
        "r_1=np.random.rand(4)\n",
        "#x2_fixed =np.sort(r_1)\n",
        "#x2_fixed=x2_fixed.tolist()\n",
        "\n",
        "#x2_fixed.insert(0,0.002)\n",
        "#x2_fixed.insert(5,1)\n",
        "#x2_fixed = np.sort(x2_fixed)\n",
        "x2_fixed=np.linspace(0,1,6)\n",
        "\n",
        "x2_modified=np.asarray(x2_fixed)\n",
        "\n",
        "total_fbank = 30\n",
        "nf=26\n",
        "\n",
        "# nf equidistant point in between 0 & 1\n",
        "xx=np.linspace(0,1,nf+2)              # will replace xx_full\n",
        "\n",
        "yv=np.zeros((total_fbank,4))                 # initialising y values for spline 1\n",
        "#y2_rand=np.zeros((total_fbank,4))            # initialising y values for spline 2\n",
        "y2_rand=np.zeros((total_fbank,6))\n",
        "\n",
        "sigma=np.zeros(total_fbank)           # 1-D arrray\n",
        "rho=np.zeros(total_fbank)\n",
        "\n",
        "EA_population=np.zeros((total_fbank,8))           # random EA population\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6deGqgeXecnm",
        "colab_type": "code",
        "outputId": "12dd5707-62bb-4485-c13f-fd5448b0134a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x2_modified"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02      , 0.01133486, 0.26456673, 0.30482349, 0.59463079,\n",
              "       1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tvc7yTHRbKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for fb in range (total_fbank):                               # total_filterbank\n",
        "       \n",
        "    #PARAMETER INITIALIZATION FOR SPLINE 1   \n",
        "    a=0.1                                            #parameter to limit range of spline in bet. 0 & 1   \n",
        "    y1=a+random()*(1-2*a)\n",
        "    delta=random()*(1-a-y1)\n",
        "    y2=y1+delta\n",
        "    \n",
        "    yv[fb][:]=[0,y1,y2,1]\n",
        "    \n",
        "    # 1st derivative calculation at end points\n",
        "    s1 = xv[0]-xv[1]         # sigma is the 1st derivative at x=0,y=0\n",
        "    s2 = xv[0]-xv[2]\n",
        "    s3 = xv[0]-xv[3]\n",
        "    s12 = s1-s2\n",
        "    s13 = s1-s3 \n",
        "    s23 = s2-s3\n",
        "    sigma[fb]=-(s1*s2/(s13*s23*s3))*yv[fb][3]+(s1*s3/(s12*s2*s23))*yv[fb][2]-(s2*s3/(s1*s12*s13))*yv[fb][1]+(1./s1+1./s2+1./s3)*yv[fb][0]\n",
        "    \n",
        "    s11 = xv[3]-xv[2]         #rho is the 1st derivative at x=1,y=1\n",
        "    s22 = xv[3]-xv[1]\n",
        "    s33 = xv[3]-xv[0]\n",
        "    s_12 = s11-s22 \n",
        "    s_13 = s11-s33 \n",
        "    s_23 = s22-s33\n",
        "    rho[fb]=-(s11*s22/(s_13*s_23*s33))*yv[fb][0]+(s11*s33/(s_12*s22*s_23))*yv[fb][1]-(s22*s33/(s11*s_12*s_13))*yv[fb][2]+(1./s11+1./s22+1./s33)*yv[fb][3]\n",
        "    \n",
        "    # PARAMETER INTIALIZATION FOR SPLINE 2\n",
        "    y2_rand[fb,:]= np.random.rand(6)*(0.9-0.25)+0.25\n",
        "    \n",
        "    #cc=[y1, delta, sigma[0,fb], rho[0,fb]]+ y2_rand[fb,:].tolist()\n",
        "    EA_population[fb,:]=[y1, delta, sigma[fb], rho[fb]]+ y2_rand[fb,1:5].tolist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTc7qBQaRbKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## SPLITTING TRAINING & TESTING DATASET \n",
        "\n",
        "fs=8000\n",
        "\n",
        "X_data = []\n",
        "Y_data = []\n",
        "\n",
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "path = '/content/drive/My Drive/MTP Project code /emodb/wav'\n",
        "\n",
        "for filename in glob.glob(os.path.join(path, '*.wav')):\n",
        "    \n",
        "    #samplerate, data = scipy.io.wavfile.read(filename,mmap=False)\n",
        "    data, sampling_rate = librosa.load(filename,sr=None)\n",
        "    # selecting speaker 15 & 16 for testing dataset\n",
        "    \n",
        "    if(filename[17:19]=='15' or filename[17:19]=='16'):\n",
        "        X_test.append(data)\n",
        "        if (filename[57]=='W'):\n",
        "            Y_test.append(0)  \n",
        "        elif(filename[57]=='L'):\n",
        "            Y_test.append(1)\n",
        "        elif(filename[57]=='E'):\n",
        "            Y_test.append(2)\n",
        "        elif(filename[57]=='A'):\n",
        "            Y_test.append(3)\n",
        "        elif(filename[57]=='F'):\n",
        "            Y_test.append(4)\n",
        "        elif(filename[57]=='T'):\n",
        "            Y_test.append(5)\n",
        "        else:                                #(filename[22]=='N')\n",
        "            Y_test.append(6)\n",
        "    else:\n",
        "        X_data.append(data)\n",
        "        if (filename[57]=='W'):\n",
        "            Y_data.append(0)  \n",
        "        elif(filename[57]=='L'):\n",
        "            Y_data.append(1)\n",
        "        elif(filename[57]=='E'):\n",
        "            Y_data.append(2)\n",
        "        elif(filename[57]=='A'):\n",
        "            Y_data.append(3)\n",
        "        elif(filename[57]=='F'):\n",
        "            Y_data.append(4)\n",
        "        elif(filename[57]=='T'):\n",
        "            Y_data.append(5)\n",
        "        else:                                #(filename[22]=='N')\n",
        "            Y_data.append(6)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zWVfIYtRbKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fs=8000\n",
        "\n",
        "X_all = []\n",
        "Y_all = []\n",
        "\n",
        "path = '/content/drive/My Drive/MTP Project code /emodb/wav'\n",
        "\n",
        "for filename in glob.glob(os.path.join(path, '*.wav')):\n",
        "    \n",
        "    data, sampling_rate = librosa.load(filename,sr=None)\n",
        "    \n",
        "    X_all.append(data)\n",
        "    if (filename[57]=='W'):\n",
        "        Y_all.append(0)  \n",
        "    elif(filename[57]=='L'):\n",
        "        Y_all.append(1)\n",
        "    elif(filename[57]=='E'):\n",
        "        Y_all.append(2)\n",
        "    elif(filename[57]=='A'):\n",
        "        Y_all.append(3)\n",
        "    elif(filename[57]=='F'):\n",
        "        Y_all.append(4)\n",
        "    elif(filename[57]=='T'):\n",
        "        Y_all.append(5)\n",
        "    else:                                #(filename[22]=='N')\n",
        "        Y_all.append(6)\n",
        "        \n",
        "X_pre_emp = []\n",
        "N_all = len(X_all)\n",
        "\n",
        "for i in range(N_all):\n",
        "    X_pre_emp.append(preemphasis(X_all[i], coeff=0.94))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPM-Dw9wRbK0",
        "colab_type": "code",
        "outputId": "d2be324f-f38e-4842-9eff-ffaae1a7fcd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_all)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "535"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R01mKQWlRbK8",
        "colab_type": "text"
      },
      "source": [
        "for this error RuntimeWarning: invalid value encountered in double_scalars, import orderedDict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNSMO2MqRbK9",
        "colab_type": "code",
        "outputId": "2213ba9a-2c9d-4942-f58d-e34eed3746cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from python_speech_features.base import delta\n",
        "\n",
        "t1 = time.perf_counter()\n",
        "\n",
        "from collections import OrderedDict\n",
        "old_settings = np.seterr(all='print')\n",
        "OrderedDict(np.geterr())\n",
        "\n",
        "gen = 1                                        # no. of generation\n",
        "valid_accuracy = np.zeros((total_fbank,gen))\n",
        "g = 0\n",
        "\n",
        "#N_data = len(X_data)\n",
        "\n",
        "#N_test = len(X_test)\n",
        "\n",
        "feat_size=42\n",
        " \n",
        "while(g<gen):\n",
        "    \n",
        "    for fb in range (total_fbank):                                           # fb=1:total_fbank\n",
        "        \n",
        "        # formation of spline 1\n",
        "        y_spline1 = splineinterpolation(xv,yv[fb][:],EA_population[fb][2], EA_population[fb][3])  \n",
        "\n",
        "        #plot(xx_mod,y_spline1)  \n",
        "        y_min= min(y_spline1)                      \n",
        "        y_max= max(y_spline1)\n",
        "\n",
        "        ## OPTIMAIZATION OF FITER FREQ. LOCATION \n",
        "        freq=np.zeros(nf+1)\n",
        "        for i in range (nf+1):                                   # i = 1:nf+1                            \n",
        "            freq[i] = (y_spline1[i]-y_min)*fs/(2*(y_max-y_min))\n",
        "\n",
        "        freq=np.sort(freq)\n",
        "\n",
        "        ## OPTIMIZATION OF FILTER AMPLITUDE\n",
        "        #y2_modified = [0.2]+ y2_rand[fb,:].tolist()+[1]\n",
        "        y2_modified = y2_rand[fb,:].tolist()\n",
        "        cs=csaps.CubicSmoothingSpline(x2_modified, y2_modified, smooth=1)\n",
        "        #cs = pchip(x2_modified, y2_modified)\n",
        "        y_spline2=cs(xx)               # xx consists nf+2 pts. including end points\n",
        "\n",
        "        #plt.plot(x2_modified, y2_modified, 'o', label='data')\n",
        "        #plt.plot(xx, cs(xx), label=\"S\")\n",
        "\n",
        "        maxi=0\n",
        "        for i in range(nf-1):                                     #i=1:nf-1\n",
        "            t=np.absolute(freq[i+2]-freq[i])\n",
        "            if(t > maxi):\n",
        "                maxi=t\n",
        "\n",
        "        N=256\n",
        "        col=math.ceil(maxi*N/fs)+10\n",
        "        filters=np.zeros((26,col))\n",
        "\n",
        "        BW=np.zeros(nf)\n",
        "        for i in range (nf):                                         # i=1:nf\n",
        "            BW[i]=6.23*pow(freq[i]/1000,2)+93.39*(freq[i]/1000)+28.52\n",
        "\n",
        "        for i in range (nf):                                               # i=1:nf\n",
        "            yline1=[]\n",
        "            yline2=[]\n",
        "\n",
        "            ff1=freq[i]-BW[i]/2\n",
        "            ff2=freq[i]+BW[i]/2\n",
        "            if(ff1>0):\n",
        "                f1=np.arange(ff1,freq[i]+1,fs/N)                             #ff1:fs/N:freq(i)\n",
        "            else:\n",
        "                f1=np.arange(0,freq[i]+1,fs/N)                              #0:fs/N:freq[i]\n",
        "\n",
        "            if(ff2>(fs/2)):\n",
        "                f2=np.arange(freq[i],(fs/2)+1,fs/N)                         #freq(i):fs/N:(fs/2);\n",
        "                freq_inter=np.intersect1d(f2,fs/2)\n",
        "                if(len(freq_inter)==0):\n",
        "                    f2=np.append(f2,fs/2)\n",
        "\n",
        "            else:\n",
        "                f2=np.arange(freq[i],ff2+1,fs/N)                                      #freq(i):fs/N:ff2;\n",
        "                freq_inter=np.intersect1d(f2,ff2)\n",
        "                if(len(freq_inter)==0):\n",
        "                    f2=np.append(f2,ff2)\n",
        "\n",
        "\n",
        "            if(freq[i]==0 or freq[i]==fs/2):\n",
        "                if(freq[i]==0):\n",
        "                    yline1.append(np.array([0]))\n",
        "                    yline2.append(-y_spline2[i]*(f2-ff2)/(ff2-freq[i]))\n",
        "                else:\n",
        "                    yline1.append(-y_spline2[i]*(f1-ff1)/(ff1-freq[i]))\n",
        "                    yline2.append(np.array([0]))\n",
        "\n",
        "            elif(ff1<0 and freq[i]!=0 and ff2 <= fs/2 ):\n",
        "                yline1.append(y_spline2[i]*f1/freq[i])\n",
        "                yline2.append(-y_spline2[i]*(f2-ff2)/(ff2-freq[i]))\n",
        "\n",
        "            elif(ff2 > (fs/2) and freq[i] < (fs/2) and ff1>0):\n",
        "                yline1.append(-y_spline2[i]*(f1-ff1)/(ff1-freq[i]))\n",
        "                yline2.append(-y_spline2[i]*(f2-(fs/2))/((fs/2)-freq[i]))\n",
        "            else:\n",
        "                yline1.append(-y_spline2[i]*(f1-ff1)/(ff1-freq[i]))\n",
        "                yline2.append(-y_spline2[i]*(f2-ff2)/(ff2-freq[i]))\n",
        "\n",
        "            L1=yline1[0].tolist()\n",
        "            L2=yline2[0].tolist()\n",
        "            yline= L1+L2\n",
        "\n",
        "            k_len=len(yline)\n",
        "            f_final=np.append(f1,f2)\n",
        "            filters[i,0:k_len]=yline\n",
        "\n",
        "            #plt.plot(f_final,filters[i,0:k_len])             # filters(i,1:k_len)\n",
        "\n",
        "        #plt.plot(freq ,y_spline2[0:-1])                  # y_spline2(1:end-1)\n",
        "        \"\"\"\n",
        "        X_set=np.zeros((N_all,feat_size))\n",
        "\n",
        "        for i in range(N_all):\n",
        "\n",
        "            y_noisy=X_pre_emp[i]\n",
        "            #X_set[i,:]=Mfcc_noisysig(y_noisy,fs,freq,filters)\n",
        "            X_set[i,:] = Mfcc_revised(y_noisy,fs,freq,filters)   #MFCC function for original signal without any noise\n",
        "\n",
        "        #X_train,X_valid,Y_train,Y_valid = data_norm_and_split(X_set,Y_all)\n",
        "        #Y_valid_pred, acc_valid = SVM_accuracy(X_train,X_valid,Y_train,Y_valid)\n",
        "        #valid_accuracy[fb,g]= acc_valid\n",
        "        \"\"\"   \n",
        "        #y_noisy = AWGN_new(X_pre_emp, 10)\n",
        "        y_noisy = X_pre_emp\n",
        "        X_set, mfcc_coeff, delta_coeff, delta_delta_coeff, frame_energy = Mfcc_revised_1(y_noisy, fs,freq,filters)\n",
        "        \n",
        "        seed = 42\n",
        "        X_shuffle, y_shuffle = shuffle(X_set, Y_all, random_state=seed)\n",
        "\n",
        "        X_train,X_test,Y_train,Y_test = data_norm_and_split(X_shuffle,y_shuffle)\n",
        "\n",
        "        valid_svc = SVC(C=100,cache_size=200, class_weight=None, coef0=0.0,\n",
        "                        decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
        "                        max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
        "                        tol=0.001, verbose=False)\n",
        "        valid_svc.fit(X_train, Y_train)\n",
        "        valid_accuracy[fb,g] = valid_svc.score(X_test, Y_test)\n",
        "        \n",
        "    if (g < gen-1):\n",
        "        EA_population, yv, y2_rand = Evolution(EA_population,valid_accuracy,yv,g)\n",
        "\n",
        "    g=g+1\n",
        "\n",
        "t2 = time.perf_counter()\n",
        "print(f'Finished in {(t2-t1)/60} minutes')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished in 6.45042947768333 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvEoJCtNTdWU",
        "colab_type": "code",
        "outputId": "23bb7892-ef22-49c5-9c0b-22b875e4a7e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "valid_accuracy"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5046729 ],\n",
              "       [0.44859813],\n",
              "       [0.43925234],\n",
              "       [0.55140187],\n",
              "       [0.54205607],\n",
              "       [0.55140187],\n",
              "       [0.57943925],\n",
              "       [0.46728972],\n",
              "       [0.43925234],\n",
              "       [0.4953271 ],\n",
              "       [0.44859813],\n",
              "       [0.51401869],\n",
              "       [0.55140187],\n",
              "       [0.43925234],\n",
              "       [0.52336449],\n",
              "       [0.48598131],\n",
              "       [0.48598131],\n",
              "       [0.4953271 ],\n",
              "       [0.5046729 ],\n",
              "       [0.47663551],\n",
              "       [0.54205607],\n",
              "       [0.47663551],\n",
              "       [0.47663551],\n",
              "       [0.45794393],\n",
              "       [0.4953271 ],\n",
              "       [0.48598131],\n",
              "       [0.41121495],\n",
              "       [0.60747664],\n",
              "       [0.48598131],\n",
              "       [0.52336449]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsJxWOi3TqQ5",
        "colab_type": "code",
        "outputId": "e9c04245-ddf0-4ba6-a419-aee97a202161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "X_set[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.13178998e+01,  1.67174343e+01,  1.23859820e+01,  1.02701475e+01,\n",
              "        4.29569600e+00,  5.78429891e+00,  6.99685851e+00,  5.34136266e+00,\n",
              "        4.60884204e+00,  5.40202065e+00,  5.35708841e+00,  5.82668539e+00,\n",
              "        5.65244387e+00,  1.83619928e-01, -7.23667831e-02, -2.79627420e-02,\n",
              "        6.27403483e-02, -3.07627034e-03, -3.22582740e-02,  4.05289682e-02,\n",
              "        2.72655700e-02,  2.36699979e-02,  5.04354834e-03,  4.08327056e-02,\n",
              "        7.96338919e-02,  1.37769035e-02,  7.96294359e-05, -2.43450746e-03,\n",
              "       -2.23266884e-04,  7.95126121e-04, -6.70483879e-04, -1.88278352e-04,\n",
              "       -1.31125411e-03, -9.27919076e-04, -7.52786632e-04, -6.55455184e-04,\n",
              "       -1.91206654e-04,  1.96886655e-04, -4.36887391e-04,  1.48287177e+00,\n",
              "        2.00319688e-01,  6.30310570e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbC_LWqCTPLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finished in 13.29455957103333 minutes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNSof01WMwBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Mfcc_revised_noisy(X_data, fs, freq, filters):\n",
        "    \n",
        "    N_data=len(X_data)\n",
        "    fs=8000   ## fs=8 kHz\n",
        "    feat_size = 42\n",
        "\n",
        "    feature_vect = np.zeros((N_data, feat_size))\n",
        "\n",
        "    mfcc_coeff = np.zeros((N_data, 13))\n",
        "    delta_coeff = np.zeros((N_data, 13))\n",
        "    delta_delta_coeff = np.zeros((N_data, 13))\n",
        "    frame_energy = np.zeros((N_data,3))\n",
        "    \n",
        "    N = 256\n",
        "    frame_len = 0.03*fs\n",
        "    M = 13          #13 point dct of a voiced frame signal\n",
        "    nf = 26\n",
        "    \n",
        "    ## using a 30-ms Hamming window with 7.5-ms step.\n",
        "    for i in range (N_data):\n",
        "      \n",
        "        frames = framesig(X_data[i], frame_len, frame_step= 0.75*frame_len, winfunc=np.hamming)\n",
        "        frame_num = len(frames)\n",
        "\n",
        "        y_fft=[]\n",
        "        energy = []\n",
        "        noisy_initial=np.zeros(N)\n",
        "        z=1\n",
        "        avg_energy = 0\n",
        "        for jk in range(frame_num):\n",
        "            temp = np.dot(frames[jk],frames[jk])\n",
        "            energy.append(temp)\n",
        "            avg_energy += temp\n",
        "\n",
        "        avg_energy = avg_energy/frame_num\n",
        "        threshold = avg_energy*0.2\n",
        "        voiced_energy = []\n",
        "\n",
        "        for fr in range(len(frames)):\n",
        "            if (energy[fr] > threshold):                     #energy[q]/frame_len < 0.2, not dividing by frame_len\n",
        "                voiced_energy.append(energy[fr])\n",
        "                temp_fft = np.absolute(np.fft.fft(frames[fr,:], N))\n",
        "                y_fft.append(temp_fft*temp_fft)      # NOTE:- TAKING THE SQUARE OF THE FFT OF EACH FRAME\n",
        "            else:\n",
        "                if(z<=3):\n",
        "                    temp_fft = np.absolute(np.fft.fft(frames[fr,:], N))\n",
        "                    noisy_initial = noisy_initial + (temp_fft*temp_fft)\n",
        "                    z=z+1\n",
        "        \n",
        "        voiced_energy = np.asarray(voiced_energy)\n",
        "        y_fft = np.asarray(y_fft)          # shape (-,256)\n",
        "        y_fft = np.transpose(y_fft)    \n",
        "        voiced_frame_no = y_fft.shape[1]\n",
        "        \n",
        "        noisy_initial=noisy_initial/3              # estimating initial noise power spectrum\n",
        "        lamda=0.97                                 #forgetting factor\n",
        "        s_t = y_fft                                # spectrum of noisy signal\n",
        "        noisy_t = np.zeros((N,voiced_frame_no))    # noise spectrum of each frame\n",
        "        noisy_t[:,0] = lamda*noisy_initial + (1-lamda)*s_t[:,0]\n",
        "\n",
        "        for qr in range (1,voiced_frame_no):                              # q=2:length(frame_energy)\n",
        "            noisy_t[:,qr] = lamda*noisy_t[:,qr-1] + (1-lamda)*s_t[:,qr]\n",
        "\n",
        "        frame_energy[i,:] = [np.mean(voiced_energy), min(voiced_energy), max(voiced_energy) ]\n",
        "\n",
        "        DCT_mat = np.zeros((voiced_frame_no,M))  \n",
        "\n",
        "        for p in range (voiced_frame_no):        # p=1:frame_no                    \n",
        "            E_spect=np.zeros(nf-3)\n",
        "            E_noisy_spect=np.zeros(nf-3)        #output of nf Mel-scaled filter when estimated noise is passed \n",
        "                                                #through filter bank\n",
        "            SNR=np.zeros(nf-3)\n",
        "            entropy=np.zeros(nf-3)\n",
        "            R=np.zeros(nf-3)\n",
        "            zeta=np.zeros(nf-3)\n",
        "            W=np.zeros(nf-3)\n",
        "\n",
        "            for q in range(nf-3):                # q=1:nf-3\n",
        "                rr=np.arange(math.floor(freq[q]*N/fs)+1,math.ceil(freq[q+2]*N/fs)+1,1)   # rows of voiced frames\n",
        "\n",
        "                E_spect[q]= filters[q,0:len(rr)].dot(y_fft[rr,p])\n",
        "                if(E_spect[q] == math.nan or E_spect[q] == math.inf):\n",
        "                    E_spect[q] = 0\n",
        "                \n",
        "                E_noisy_spect[q]= filters[q,0:len(rr)].dot(noisy_t[rr,p])\n",
        "            \n",
        "                x=np.absolute(np.transpose(y_fft[rr,p]))\n",
        "                for j in range (len(x)):                                    #j=1:length(x)\n",
        "                    x_pmf=x[j]/sum(x)\n",
        "                    entropy[q]=entropy[q]-x_pmf*math.log(x_pmf)\n",
        "            \n",
        "            \n",
        "            ## sub-band wiener filtering        \n",
        "            tap=20              ## no. of taps of wiener filter\n",
        "            Rxy=np.correlate(E_spect,E_spect-E_noisy_spect)   # corr. b/t \n",
        "            Ry=np.correlate(E_spect,E_spect)            # noisy signal correlation\n",
        "            m=round(len(Rxy)/2)\n",
        "            Rxy=Rxy[m :m+tap-1]\n",
        "            Ry=Ry[m:m+tap-1]\n",
        "            R_Y=toeplitz(Ry)\n",
        "            h=np.matmul(inv(R_Y),np.transpose(Rxy))             # Filter Coefficients\n",
        "            E_SWF=np.convolve(E_spect,h)            # enhanced filterbank energy after mel sub-band wiener filtering\n",
        "            #SWF- sub band wiener filtering\n",
        "\n",
        "            ## Calculation of SNR and Entropy for mel sub-bands\n",
        "            for tr in range(nf-3):                                 #i=1:nf-3\n",
        "                SNR[tr]=np.sqrt(1+(E_SWF[tr]/E_noisy_spect[tr]))\n",
        "                R[tr]=SNR[tr]/entropy[tr]                       # SNR to Entropy ratio for ith mel frequency sub-band\n",
        "\n",
        "            np.nan_to_num(R,copy=False)          # converting nan to zero and inf to large finite no.\n",
        "            mean_R=np.mean(R)\n",
        "            sigma_R=np.sqrt(np.var(R))\n",
        "\n",
        "            for bb in range(nf-3):                            # i=1:nf-3\n",
        "                zeta[bb]=1-(1/(1+math.exp(-(R[bb]-mean_R)/sigma_R)))  \n",
        "                W[bb]=1-math.exp(-R[bb]/zeta[bb])\n",
        "\n",
        "\n",
        "            #log_ESF=[math.log1p(i) for i in E_SWF]\n",
        "            E_SWF=np.absolute(E_SWF)\n",
        "            for kk in range (len(E_SWF)):\n",
        "                if(E_SWF[kk]!=0):\n",
        "                    E_SWF[kk]=math.log(E_SWF[kk])\n",
        "                else:\n",
        "                    E_SWF[kk]=0\n",
        "\n",
        "            spect=W*E_SWF\n",
        "            DCT_mat[p,:]=np.absolute(scipy.fftpack.dct(spect,n=M))\n",
        "            \n",
        "        delta_feat = delta(DCT_mat, N = len(DCT_mat))\n",
        "        delta_delta_feat = delta(delta_feat, N = len(DCT_mat))\n",
        "\n",
        "        mfcc_coeff[i,:] = np.mean(DCT_mat,axis=0)\n",
        "        delta_coeff[i,:] = np.mean(delta_feat, axis = 0)\n",
        "        delta_delta_coeff[i,:] = np.mean(delta_delta_feat, axis = 0)\n",
        "\n",
        "        feature_vect[i,:] = np.hstack((mfcc_coeff[i,:], delta_coeff[i,:], delta_delta_coeff[i,:],\n",
        "                                             frame_energy[i,:]))\n",
        "    \n",
        "    return feature_vect, mfcc_coeff, delta_coeff, delta_delta_coeff, frame_energy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J3FB4mdqx8J",
        "colab_type": "code",
        "outputId": "82f43541-46ba-429a-d7e9-99f0579d8458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "valid_accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.43925234, 0.57009346, 0.57943925, ..., 0.63551402, 0.63551402,\n",
              "        0.63551402],\n",
              "       [0.52336449, 0.57009346, 0.53271028, ..., 0.62616822, 0.62616822,\n",
              "        0.62616822],\n",
              "       [0.4953271 , 0.55140187, 0.57009346, ..., 0.62616822, 0.62616822,\n",
              "        0.62616822],\n",
              "       ...,\n",
              "       [0.48598131, 0.52336449, 0.54205607, ..., 0.61682243, 0.48598131,\n",
              "        0.61682243],\n",
              "       [0.42990654, 0.52336449, 0.48598131, ..., 0.42056075, 0.52336449,\n",
              "        0.61682243],\n",
              "       [0.4953271 , 0.51401869, 0.43925234, ..., 0.4953271 , 0.5046729 ,\n",
              "        0.44859813]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE-F8eFcxiHL",
        "colab_type": "code",
        "outputId": "bacb4906-6d4f-48da-b2c7-6d5f9310ae49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "valid_accuracy[:,0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.43925234, 0.52336449, 0.4953271 , 0.44859813, 0.53271028,\n",
              "       0.46728972, 0.39252336, 0.57009346, 0.54205607, 0.52336449,\n",
              "       0.5046729 , 0.46728972, 0.47663551, 0.4953271 , 0.52336449,\n",
              "       0.55140187, 0.57009346, 0.51401869, 0.43925234, 0.53271028,\n",
              "       0.47663551, 0.42056075, 0.43925234, 0.5046729 , 0.51401869,\n",
              "       0.47663551, 0.53271028, 0.48598131, 0.42990654, 0.4953271 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UeKwImRRbLD",
        "colab_type": "code",
        "outputId": "0b47e4ba-9fd6-46cb-a0a7-491622c94521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.max(valid_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6355140186915887"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP1D5Cll22X5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EA_population"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1EkOCxcYUt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def Mfcc_revised_1(X_data, fs, freq, filters):\n",
        "    \n",
        "    N_data=len(X_data)\n",
        "    fs=8000   ## fs=8 kHz\n",
        "    feat_size = 42\n",
        "\n",
        "    feature_vect = np.zeros((N_data, feat_size))\n",
        "\n",
        "    mfcc_coeff = np.zeros((N_data, 13))\n",
        "    delta_coeff = np.zeros((N_data, 13))\n",
        "    delta_delta_coeff = np.zeros((N_data, 13))\n",
        "    frame_energy = np.zeros((N_data,3))\n",
        "    \n",
        "    N = 256\n",
        "    frame_len = 0.03*fs\n",
        "    M = 13          #13 point dct of a voiced frame signal\n",
        "    nf = 26\n",
        "    \n",
        "    ## using a 30-ms Hamming window with 7.5-ms step.\n",
        "    for i in range (len(X_data)):\n",
        "    \n",
        "        \n",
        "        frames = framesig(X_data[i], frame_len, frame_step= 0.75*frame_len, winfunc=np.hamming)\n",
        "\n",
        "        frame_num = len(frames)\n",
        "\n",
        "        y_fft=[]\n",
        "        energy = []\n",
        "\n",
        "        avg_energy = 0\n",
        "        for jk in range(frame_num):\n",
        "            temp = np.dot(frames[jk],frames[jk])\n",
        "            energy.append(temp)\n",
        "            avg_energy += temp\n",
        "\n",
        "        avg_energy = avg_energy/frame_num\n",
        "        threshold = avg_energy*0.3\n",
        "        voiced_energy = []\n",
        "\n",
        "        for fr in range(len(frames)):\n",
        "            if (energy[fr] > threshold):                     #energy[q]/frame_len < 0.2, not dividing by frame_len\n",
        "                voiced_energy.append(energy[fr])\n",
        "                temp_fft = np.absolute(np.fft.fft(frames[fr,:], N))\n",
        "                y_fft.append(temp_fft*temp_fft)          \n",
        "\n",
        "        voiced_energy = np.asarray(voiced_energy)\n",
        "        y_fft = np.asarray(y_fft)          # shape (-,256)\n",
        "        y_fft = np.transpose(y_fft)\n",
        "\n",
        "        frame_energy[i,:] = [np.mean(voiced_energy), min(voiced_energy), max(voiced_energy) ]\n",
        "\n",
        "        voiced_frame_no = y_fft.shape[1]\n",
        "        \n",
        "        DCT_mat = np.zeros((voiced_frame_no,M))  \n",
        "\n",
        "        for p in range (voiced_frame_no):        # p=1:frame_no                    \n",
        "            E_spect=np.zeros(nf-3)          \n",
        "\n",
        "            for q in range(nf-3):                # q=1:nf-3\n",
        "                rr=np.arange(math.floor(freq[q]*N/fs)+1,math.ceil(freq[q+2]*N/fs)+1,1)   # rows of voiced frames\n",
        "\n",
        "                E_spect[q]= filters[q,0:len(rr)].dot(y_fft[rr,p])\n",
        "                if(E_spect[q] == math.nan or E_spect[q] == math.inf):\n",
        "                    E_spect[q] = 0\n",
        "\n",
        "            for ee in range (len(E_spect)):\n",
        "                if(E_spect[ee]!=0 ):\n",
        "                    E_spect[ee] = math.log(np.absolute(E_spect[ee]))\n",
        "                else:\n",
        "                    E_spect[ee] = 0\n",
        "\n",
        "            DCT_mat[p,:]=np.absolute(scipy.fftpack.dct(E_spect,n=M))\n",
        "\n",
        "\n",
        "        delta_feat = delta(DCT_mat, N = len(DCT_mat))\n",
        "        delta_delta_feat = delta(delta_feat, N = len(DCT_mat))\n",
        "\n",
        "        mfcc_coeff[i,:] = np.mean(DCT_mat,axis=0)\n",
        "        delta_coeff[i,:] = np.mean(delta_feat, axis = 0)\n",
        "        delta_delta_coeff[i,:] = np.mean(delta_delta_feat, axis = 0)\n",
        "\n",
        "        feature_vect[i,:] = np.hstack((mfcc_coeff[i,:], delta_coeff[i,:], delta_delta_coeff[i,:],\n",
        "                                             frame_energy[i,:]))\n",
        "    \n",
        "    return feature_vect, mfcc_coeff, delta_coeff, delta_delta_coeff, frame_energy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "narjTHs_RbLL",
        "colab_type": "text"
      },
      "source": [
        "CLASSIFICATION ON TESTING TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydzPgAbqRbLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "# Import GridsearchCV from Scikit Learn\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuNdQc9rw9r6",
        "colab_type": "code",
        "outputId": "8a68f06a-2b3e-4c30-dff7-093b7f0f796b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "valid_accuracy[:,0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.43925234, 0.52336449, 0.4953271 , 0.44859813, 0.53271028,\n",
              "       0.46728972, 0.39252336, 0.57009346, 0.54205607, 0.52336449,\n",
              "       0.5046729 , 0.46728972, 0.47663551, 0.4953271 , 0.52336449,\n",
              "       0.55140187, 0.57009346, 0.51401869, 0.43925234, 0.53271028,\n",
              "       0.47663551, 0.42056075, 0.43925234, 0.5046729 , 0.51401869,\n",
              "       0.47663551, 0.53271028, 0.48598131, 0.42990654, 0.4953271 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U98zVBDuK_y",
        "colab_type": "code",
        "outputId": "66820481-e867-4055-ec78-6b1ae3748889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "valid_accuracy[:,gen-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.63551402, 0.62616822, 0.62616822, 0.62616822, 0.62616822,\n",
              "       0.62616822, 0.61682243, 0.61682243, 0.61682243, 0.61682243,\n",
              "       0.61682243, 0.61682243, 0.61682243, 0.61682243, 0.61682243,\n",
              "       0.61682243, 0.61682243, 0.61682243, 0.61682243, 0.61682243,\n",
              "       0.52336449, 0.61682243, 0.46728972, 0.61682243, 0.62616822,\n",
              "       0.44859813, 0.62616822, 0.61682243, 0.61682243, 0.44859813])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3qUi3uJw7ic",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noLkZD8lud7p",
        "colab_type": "code",
        "outputId": "686c5c98-69ec-4244-f53a-06a50883b230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "ind_sort = np.argsort(valid_accuracy[:,gen-1])\n",
        "ind_sort"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29, 25, 22, 20, 27, 23, 21, 19, 18, 17, 16, 15, 28, 14, 12, 11, 10,\n",
              "        9,  8,  7,  6, 13,  5,  4,  3, 24,  2, 26,  1,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cikO-TXSuK9C",
        "colab_type": "code",
        "outputId": "c9d3126e-f092-4db7-c300-53cf50ea09c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best4_ind = ind_sort[::-1][:4]\n",
        "best4_ind"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1, 26,  2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLknoMF6vp1r",
        "colab_type": "code",
        "outputId": "9d7a45d7-ebca-4b63-e6ef-66073996f65d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EA_population"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.70196009, 0.02913378, 0.91429424, 0.87976032, 0.10147259,\n",
              "        0.06363334, 0.73114331, 0.26414956],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.91664851,\n",
              "        0.58516519, 0.54957741, 0.1991084 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.91664851,\n",
              "        0.65029055, 0.73114331, 0.1991084 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.91664851,\n",
              "        0.58516519, 0.54957741, 0.1991084 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.91664851,\n",
              "        0.58516519, 0.93612318, 0.1991084 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.91664851,\n",
              "        0.58516519, 0.54957741, 0.1991084 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.96017992,\n",
              "        0.06363334, 0.99763042, 0.67400756],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.289966  ,\n",
              "        0.06363334, 0.73114331, 0.38488255],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.289966  ,\n",
              "        0.06363334, 0.73114331, 0.2436608 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.96017992,\n",
              "        0.06363334, 0.73114331, 0.2436608 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.91664851,\n",
              "        0.06363334, 0.73114331, 0.1991084 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.289966  ,\n",
              "        0.06363334, 0.73114331, 0.26414956],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.289966  ,\n",
              "        0.06363334, 0.14269161, 0.26414956],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.289966  ,\n",
              "        0.06363334, 0.81019574, 0.2436608 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.96017992,\n",
              "        0.06363334, 0.73114331, 0.2436608 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.91664851,\n",
              "        0.06363334, 0.99763042, 0.67400756],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.91664851,\n",
              "        0.06363334, 0.99763042, 0.67400756],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.289966  ,\n",
              "        0.06363334, 0.7033992 , 0.2436608 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.96017992,\n",
              "        0.06363334, 0.73114331, 0.2436608 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.289966  ,\n",
              "        0.06363334, 0.73114331, 0.74210096],\n",
              "       [0.36337946, 0.26858846, 0.34707617, 2.82318884, 0.91664851,\n",
              "        0.06363334, 0.54957741, 0.1991084 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.289966  ,\n",
              "        0.06363334, 0.73114331, 0.74210096],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 0.98072413, 0.289966  ,\n",
              "        0.80097346, 0.73114331, 0.2436608 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.96017992,\n",
              "        0.06363334, 0.99763042, 0.35367317],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.91664851,\n",
              "        0.58516519, 0.93612318, 0.1991084 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 0.24187732, 0.96017992,\n",
              "        0.58516519, 0.74241732, 0.1991084 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.91664851,\n",
              "        0.58516519, 0.68213304, 0.1991084 ],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.91664851,\n",
              "        0.06363334, 0.99763042, 0.67400756],\n",
              "       [0.36337946, 0.26858846, 0.34822643, 2.82318884, 0.289966  ,\n",
              "        0.06363334, 0.81019574, 0.2436608 ],\n",
              "       [0.72675893, 0.06435476, 0.69645286, 5.64637767, 0.59983277,\n",
              "        0.12726668, 0.9109576 , 0.98576175]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byS962IoRbLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tt1 = time.perf_counter()\n",
        "\n",
        "## CHOOSING 4 BEST FILTERBANKS FROM THE POPULATION \n",
        "\n",
        "best_fbank = 4\n",
        "\"\"\"\n",
        "best_feature_vect = np.zeros((best_fbank, feat_size))\n",
        "best_mfcc_coeff = np.zeros((best_fbank, 13))\n",
        "best_delta_coeff = np.zeros((best_fbank, 13))\n",
        "best_delta_delta_coeff = np.zeros((best_fbank, 13))\n",
        "best_frame_energy = np.zeros((best_fbank,3))\n",
        "\"\"\"\n",
        "ind_sort = np.argsort(valid_accuracy[:,gen-1])\n",
        "best4_ind = ind_sort[::-1][:4]                          ## select the last for ele. of ind_sort\n",
        "\n",
        "ESFB=np.zeros((best_fbank,8))\n",
        "\n",
        "for i in range(best_fbank):\n",
        "    ESFB[i,:]=EA_population[best4_ind[i],:]\n",
        "    \n",
        "                          \n",
        "accuracy_fbank=np.zeros((best_fbank,2))\n",
        "yv_test=np.zeros((best_fbank,4))\n",
        "\n",
        "for bfb in range(best_fbank):                             #cc=[y1, delta, sigma[0,fb], rho[0,fb]]+ y2_rand[fb,:].tolist()\n",
        "    yv_test[bfb,1]=ESFB[bfb,0]                            # yv[fb][:]=[0,y1,y2,1]\n",
        "    yv_test[bfb,2]=ESFB[bfb,0]+ESFB[bfb,1]\n",
        "\n",
        "yv_test[:,3]=1\n",
        "yv2_test=ESFB[:,4:]\n",
        "\n",
        "for fb in range(best_fbank):\n",
        "    \n",
        "    # formation of spline 1\n",
        "    y_spline1_t = splineinterpolation(xv,yv_test[fb,:],ESFB[fb,2], ESFB[fb,3])  \n",
        "\n",
        "\n",
        "    #plot(xx_mod,y_spline1)  \n",
        "\n",
        "    y_min_t = min(y_spline1_t)                      \n",
        "    y_max_t = max(y_spline1_t)\n",
        "\n",
        "    ## OPTIMAIZATION OF FITER FREQ. LOCATION \n",
        "\n",
        "    freq_t=np.zeros(nf+1)\n",
        "    for i in range (nf+1):                                   # i = 1:nf+1                            \n",
        "        freq_t[i] = (y_spline1_t[i]-y_min_t)*fs/ (2*(y_max_t-y_min_t))\n",
        "\n",
        "    freq_t=np.sort(freq_t)\n",
        "\n",
        "    ## OPTIMIZATION OF FILTER AMPLITUDE\n",
        "\n",
        "    y2_mod_t = [0.2]+ yv2_test[fb,:].tolist()+[1]\n",
        "    cs_t = pchip(x2_modified, y2_mod_t)\n",
        "    y_spline2_t=cs_t(xx)               # xx consists nf+2 pts. including end points\n",
        "\n",
        "    #plt.plot(x2_modified, y2_modified, 'o', label='data')\n",
        "    #plt.plot(xx, cs(xx), label=\"S\")\n",
        "\n",
        "\n",
        "\n",
        "    maxi_t=0\n",
        "    for i in range(nf-1):                                     #i=1:nf-1\n",
        "        t=np.absolute(freq_t[i+2]-freq_t[i])\n",
        "        if(t > maxi_t):\n",
        "            maxi_t=t\n",
        "\n",
        "    N=256\n",
        "    col_t=math.ceil(maxi_t*N/fs)+10\n",
        "    filters_t=np.zeros((26,col_t))\n",
        "\n",
        "    BW_t=np.zeros(nf)\n",
        "    for i in range (nf):                                         # i=1:nf\n",
        "        BW_t[i]=6.23*pow(freq_t[i]/1000,2)+93.39*(freq_t[i]/1000)+28.52\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(3,3))\n",
        "    #plt.subplot(2,2)\n",
        "    \n",
        "    for i in range (nf):                                               # i=1:nf\n",
        "        yline1_t = []\n",
        "        yline2_t = []\n",
        "\n",
        "        ff1_t = freq_t[i]-BW_t[i]/2\n",
        "        ff2_t = freq_t[i]+BW_t[i]/2\n",
        "        if(ff1_t > 0):\n",
        "            f1_t = np.arange(ff1_t, freq_t[i]+1, fs/N)                             #ff1:fs/N:freq(i)\n",
        "        else:\n",
        "            f1_t = np.arange(0, freq_t[i]+1, fs/N)                                                        #0:fs/N:freq[i]\n",
        "\n",
        "        if(ff2_t > (fs/2)):\n",
        "            f2_t = np.arange(freq_t[i],(fs/2)+1, fs/N)                         #freq(i):fs/N:(fs/2);\n",
        "            freq_inter_t = np.intersect1d(f2_t, fs/2)\n",
        "            if(len(freq_inter_t) == 0):\n",
        "                f2_t = np.append(f2_t, fs/2)\n",
        "\n",
        "        else:\n",
        "            f2_t = np.arange(freq_t[i], ff2_t+1, fs/N)                                      #freq(i):fs/N:ff2;\n",
        "            freq_inter_t = np.intersect1d(f2_t, ff2_t)\n",
        "            if(len(freq_inter_t) == 0):\n",
        "                f2_t = np.append(f2_t, ff2_t)\n",
        "\n",
        "\n",
        "        if(freq_t[i] == 0 or freq_t[i] == fs/2):\n",
        "            if(freq_t[i]==0):\n",
        "                yline1_t.append(np.array([0]))\n",
        "                yline2_t.append(-y_spline2_t[i]*(f2_t-ff2_t)/(ff2_t-freq_t[i]))\n",
        "            else:\n",
        "                yline1_t.append(-y_spline2_t[i]*(f1_t-ff1_t)/(ff1_t-freq_t[i]))\n",
        "                yline2_t.append(np.array([0]))\n",
        "\n",
        "        elif(ff1_t<0 and freq_t[i]!=0 and ff2_t <= fs/2 ):\n",
        "            yline1_t.append(y_spline2_t[i]*f1_t / freq_t[i])\n",
        "            yline2_t.append(-y_spline2_t[i]*(f2_t-ff2_t) / (ff2_t-freq_t[i]))\n",
        "\n",
        "        elif(ff2_t > (fs/2) and freq_t[i] < (fs/2) and ff1_t > 0):\n",
        "            yline1_t.append(-y_spline2_t[i]*(f1_t-ff1_t) / (ff1_t-freq_t[i]))\n",
        "            yline2_t.append(-y_spline2_t[i]*(f2_t-(fs/2)) / ((fs/2)-freq_t[i]))\n",
        "        else:\n",
        "            yline1_t.append(-y_spline2_t[i]*(f1_t-ff1_t) / (ff1_t-freq_t[i]))\n",
        "            yline2_t.append(-y_spline2_t[i]*(f2_t-ff2_t) / (ff2_t-freq_t[i]))\n",
        "\n",
        "\n",
        "        L1_t = yline1_t[0].tolist()\n",
        "        L2_t = yline2_t[0].tolist()\n",
        "        yline_t = L1_t+L2_t\n",
        "\n",
        "        k_len_t = len(yline_t)\n",
        "        f_final_t = np.append(f1_t,f2_t)\n",
        "        filters_t[i,0:k_len_t] = yline_t\n",
        "        plt.plot(f_final_t, filters_t[i,0:k_len_t])             # filters(i,1:k_len)\n",
        "\n",
        "\n",
        "    plt.plot(freq_t , y_spline2_t[0:-1])                  # y_spline2(1:end-1)\n",
        "    \n",
        "    #X_set_train = np.zeros((N_data, feat_size))\n",
        "    #X_set_test = np.zeros((N_test, feat_size))\n",
        "\n",
        "    #feature_set = np.zeros((len(X_all), feat_size))\n",
        "    \n",
        "    \"\"\"\n",
        "    for i in range(N_data):\n",
        "\n",
        "        # y_noisy,STD_n=AWGN(X_data[i],10)\n",
        "        y_noisy_t = X_data[i]\n",
        "        X_set_train[i,:] = Mfcc(y_noisy_t, fs, freq_t, filters_t)                       #extracting mfcc coeff.   \n",
        "        \n",
        "    for i in range(N_test):\n",
        "        X_set_test[i,:] = Mfcc(X_test[i], fs, freq_t, filters_t)\n",
        "    \n",
        "    X_train_t, X_valid_t, Y_train_t, Y_valid_t = data_norm_and_split(X_set_train,Y_data)\n",
        "    \n",
        "    X_test_data = data_norm(X_set_test)\n",
        "    Y_test_data = np.asarray(Y_test)\n",
        "\n",
        "    Y_test_pred, acc = SVM_accuracy(X_train_t,X_test_data,Y_train_t,Y_test_data)\n",
        "    accuracy_test[fb] = acc\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    for i in range(len(X_all)):\n",
        "        feature_set[i,:] = Mfcc(X_pre_emp[i], fs, freq_t, filters_t)\n",
        "    \"\"\"\n",
        "    best_feature_set, best_mfcc_coeff, best_delta_coeff, best_delta_delta_coeff, best_frame_energy = Mfcc_revised_1(X_pre_emp, fs, freq_t, filters_t)\n",
        "\n",
        "    #print(colored(\"The observation is made for the best filter bank {}\".format (fb), 'red', 'on_grey'), \"\\n\")\n",
        "    #accuracy_fbank[fb,0], accuracy_fbank[fb,1] = parameter_tuning(best_feature_set, Y_all)\n",
        "    \n",
        "    seed = 42\n",
        "    X_shuffle, y_shuffle = shuffle(best_feature_set, Y_all, random_state=seed)\n",
        "    X_train_t, X_valid_t, Y_train_t, Y_valid_t = data_norm_and_split(X_shuffle,y_shuffle)\n",
        "\n",
        "    Y_test_pred, acc = SVM_accuracy(X_train_t, X_valid_t, Y_train_t, Y_valid_t)\n",
        "    accuracy_test[fb] = acc\n",
        "\n",
        "\n",
        "tt2 = time.perf_counter()\n",
        "print(f'Finished in {(tt2-tt1)/60} minutes')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUpLlLtyb-WY",
        "colab_type": "code",
        "outputId": "e9fceaa5-5a4e-4d01-a634-6d3829a0421e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "accuracy_fbank"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e656984d9743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_fbank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracy_fbank' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n_ahrXwRbLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parameter_tuning(feature_vect, Y_data):\n",
        "    \n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X = scaler.fit_transform(feature_vect)\n",
        "    y = np.asarray(Y_data)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=27)\n",
        "       \n",
        "    param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['linear','rbf', 'poly', 'sigmoid']}\n",
        "    \n",
        "    grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2, cv = 5)\n",
        "    grid.fit(X_train,y_train)\n",
        "    print(\"best_estimator :- \", grid.best_estimator_, \"\\n\")\n",
        "\n",
        "    grid_predictions = grid.predict(X_test)\n",
        "    print(\"confusion_matrix :-\" , confusion_matrix(y_test,grid_predictions))\n",
        "    print(\"classification_report :-\" , classification_report(y_test,grid_predictions))\n",
        "    print(\"score:- \" , grid.score(X_test,y_test),\"\\n\")\n",
        "\n",
        "\n",
        "    scores_best = {\"True\":[], \"False\": []}\n",
        "    shuffs = [True, False]\n",
        "\n",
        "    for shuff in shuffs:\n",
        "        print(colored(\"The observation is made when shuffle is {}\".format (shuff), 'red', 'on_grey'), \"\\n\")\n",
        "        \"\"\"\n",
        "        best_svc = SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
        "            decision_function_shape='ovr', degree=3, gamma=0.01, kernel='sigmoid',\n",
        "            max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
        "            tol=0.001, verbose=False)\n",
        "        \"\"\"\n",
        "        best_svc = grid.best_estimator_\n",
        "\n",
        "        # k-fold cross validation\n",
        "\n",
        "        cv = KFold(n_splits=10, random_state=42, shuffle = shuff)\n",
        "        for train_index, test_index in cv.split(X):\n",
        "\n",
        "            #print(\"Train Index: \", train_index, \"\\n\")\n",
        "            #print(\"Test Index: \", test_index)\n",
        "\n",
        "            X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
        "            best_svc.fit(X_train, y_train)\n",
        "            if(shuff == True):\n",
        "                scores_best[\"True\"].append(best_svc.score(X_test, y_test))\n",
        "            else:\n",
        "                scores_best[\"False\"].append(best_svc.score(X_test, y_test))\n",
        "\n",
        "            print(\"\\n \")\n",
        "        \n",
        "    #scores_best\n",
        "    Score_shuff_true=scores_best[\"True\"]\n",
        "    Score_shuff_false = scores_best[\"False\"]\n",
        "    print(\"Score_shuff_true :- \", np.mean(Score_shuff_true))\n",
        "    print(\"Score_shuff_false :- \", np.mean(Score_shuff_false))\n",
        "    \n",
        "    return np.mean(Score_shuff_true), np.mean(Score_shuff_false)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTH9t2oRRbL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SVM_accuracy(X_train,X_valid,Y_train,Y_valid):\n",
        "    y_pred=[]\n",
        "    accuracy=[]\n",
        "    \n",
        "    for kernel in ('linear', 'rbf', 'poly'):\n",
        "        clf = SVC(kernel=kernel, gamma=10)\n",
        "        clf.fit(X_train, Y_train)\n",
        "        #print(clf.score(X_valid,Y_valid))\n",
        "        \n",
        "        accuracy.append(clf.score(X_valid,Y_valid))\n",
        "        y_pred.append(clf.predict(X_valid))\n",
        "    \n",
        "    ## for confusion matrix\n",
        "    #cm1 = ConfusionMatrix(actual_vector=Y_valid, predict_vector=y_pred[0])\n",
        "    \n",
        "    return y_pred[0], accuracy[0]                   # here we are returning o/p from linear kernel\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0XAyq6lRbL9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "cm1 = ConfusionMatrix(actual_vector=Y_valid, predict_vector=y_pred[0])\n",
        "\n",
        "print(cm1)\n",
        "\n",
        "cm1.classes\n",
        "\n",
        "cm1.table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEMMoWHsRbL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_norm(X_test):\n",
        "    scaler = preprocessing.StandardScaler()\n",
        "    Xt_trans = scaler.fit_transform(X_test)\n",
        "    \n",
        "    return X_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EucpqpipRbMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_norm_and_split(X_set,Y_data):\n",
        "    Xx = X_set\n",
        "    yy = np.asarray(Y_data)\n",
        "\n",
        "    X_t, X_v, y_t, y_v = train_test_split(Xx,yy,test_size=0.2,random_state=27)\n",
        "\n",
        "    scaler = preprocessing.StandardScaler()\n",
        "    Xt_trans = scaler.fit_transform(X_t)\n",
        "    Xv_trans = scaler.fit_transform(X_v)\n",
        "    \n",
        "    return Xt_trans,Xv_trans,y_t,y_v\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2cF7Gw4RbMI",
        "colab_type": "text"
      },
      "source": [
        "##### data normalization with sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "##### fit scaler on training data\n",
        "norm = MinMaxScaler().fit(X_train)\n",
        "\n",
        "##### transform training data\n",
        "X_train_norm = norm.transform(X_train)\n",
        "\n",
        "##### transform testing dataabs\n",
        "X_test_norm = norm.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2xzjogeRbMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splineinterpolation(xv,yv,yp1,ypn):\n",
        "\n",
        "    y2=np.zeros(4)         #2nd derivative\n",
        "    n=len(y2)\n",
        "    u=np.zeros(n-1)\n",
        "    \n",
        "    if (yp1 > 0.99e99):\n",
        "        y2[0]=0\n",
        "        u[0]=0\n",
        "    else:\n",
        "        y2[0]=yp1\n",
        "        u[0]=(3.0/(xv[1]-xv[0]))*((yv[1]-yv[0])/(xv[1]-xv[0]-yp1))\n",
        "    \n",
        "\n",
        "    for i in range(1,n-1):                          #i=2:n-1\n",
        "        sig=(xv[i]-xv[i-1])/(xv[i+1]-xv[i-1])\n",
        "        p=sig*y2[i-1]+2.0\n",
        "        y2[i]=(sig-1.0)/p\n",
        "        u[i]=(yv[i+1]-yv[i])/(xv[i+1]-xv[i]) - (yv[i]-yv[i-1])/(xv[i]-xv[i-1])\n",
        "        u[i]=(6.0*u[i]/(xv[i+1]-xv[i-1])-sig*u[i-1])/p\n",
        "    \n",
        "\n",
        "    if(ypn > 0.99e99):\n",
        "        qn=0\n",
        "        un=0\n",
        "    else:\n",
        "        qn=0.5\n",
        "        un=(3.0/(xv[n-1]-xv[n-2]))*(ypn-(yv[n-1]-yv[n-2])/(xv[n-1]-xv[n-2]))\n",
        "    \n",
        "    y2[n-1]=(un-qn*u[n-2])/(qn*y2[n-2]+1.0)\n",
        "                                     \n",
        "    for k in np.arange(n-2,-1,-1):                                        # k=n-1:-1:1\n",
        "        y2[k]=y2[k]*y2[k+1]+u[k]\n",
        "    \n",
        "\n",
        "    nf=26\n",
        "    jl=1\n",
        "    klo=jl\n",
        "    khi=jl+1\n",
        "    xx=xv\n",
        "    h=xx[khi]-xx[klo]\n",
        "                                     \n",
        "    #if(h==0) % throw warning\n",
        "                                     \n",
        "    x = np.linspace(0,1,nf+3)          # nf+1 points bt 0 & 1, excluding 0 & 1\n",
        "    x=np.delete(x,[0])\n",
        "    x=np.delete(x,[27])\n",
        "                            \n",
        "    y=np.zeros(nf+1)\n",
        "    \n",
        "    for i in range (nf+1):                                 # i=1:nf+1\n",
        "        a=(xx[khi]-x[i])/h\n",
        "        b=(x[i]-xx[klo])/h\n",
        "        y[i]=a*yv[klo]+b*yv[khi]+((a*a*a-a)*y2[klo]+(b*b*b-b)*y2[khi])*(h*h)/6.0\n",
        "        if(y[i]<0):\n",
        "            y[i]=0\n",
        "        if(y[i]>1):\n",
        "            y[i]=1\n",
        "        \n",
        "    #x=[0,x,1];\n",
        "    #y=[0,y,1];\n",
        "    # plot(x,y);\n",
        "\n",
        "    return y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2PWS-cNRbMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AWGN_new(X,snr):\n",
        "    N = len(X)\n",
        "    y_noisy = []\n",
        "    for i in range(N): \n",
        "        x=X[i]\n",
        "        sig_power = np.mean(np.abs(x.tolist())**2)\n",
        "        sig_db = 10 * np.log10(sig_power)\n",
        "        noise_db = sig_db -snr\n",
        "        noise_power = 10 ** (noise_db / 10)\n",
        "        # Generate an sample of white noise\n",
        "        mean_noise = 0\n",
        "        noise = np.random.normal(mean_noise, np.sqrt(noise_power), len(x))\n",
        "        # Noise up the original signal\n",
        "        y_noisy.append(x + noise)\n",
        "    return y_noisy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTzr32YRRbMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Evolution(EA_population,accuracy,yv,g):\n",
        "    import random\n",
        "    total_fbank=30\n",
        "    current_member = 1\n",
        "    lamda=20                                                                #selecting lamda individuals from 30 chromosomes\n",
        "    chromo_size=8\n",
        "    mating_pool=np.zeros((total_fbank,chromo_size))\n",
        "    val =max(accuracy[:,g])\n",
        "    best_indx=accuracy[:,g].tolist().index(max(accuracy[:,g]))\n",
        "    best_individual=EA_population[best_indx,:]                             # best individual out of 30 individuals\n",
        "    mating_pool[0,:]=best_individual                                       #elitist strategy\n",
        "    #qq=np.zeros(lamda-1)\n",
        "    qq=[]\n",
        "    while current_member <lamda:\n",
        "        rand_ind=random.sample(range(total_fbank), 10)                     # picking 10 individuals randomly out of 30\n",
        "        best=0\n",
        "        counter=0\n",
        "        for j in range(len(rand_ind)):\n",
        "            if current_member==1 and accuracy[rand_ind[j],g] > best and rand_ind[j]!=best_indx:\n",
        "                best= accuracy[rand_ind[j],g]\n",
        "                counter=j\n",
        "            elif current_member >1 and accuracy[rand_ind[j],g] > best and rand_ind[j]!=best_indx:\n",
        "                inter=list(set(qq) & set(rand_ind))\n",
        "                if not inter:\n",
        "                    best=accuracy[rand_ind[j],g]\n",
        "                    counter=j\n",
        "                else:\n",
        "                    continue\n",
        "               \n",
        "        if (counter>0):\n",
        "            mating_pool[current_member,:]=EA_population[rand_ind[counter],:]\n",
        "            qq.append(rand_ind[counter])\n",
        "            current_member+=1\n",
        "      \n",
        "    ## ONE POINT CROSSOVER\n",
        "      \n",
        "    slt=np.random.permutation(20) \n",
        "    select=slt.tolist()\n",
        "    select.remove(0) \n",
        "    kk=20\n",
        "    total=list(range(0,30))\n",
        "    r=list(set(total).difference(set(qq)))\n",
        "    if best_indx in r:\n",
        "        r.remove(best_indx)\n",
        "    n=len(r)\n",
        "    \n",
        "    for q in range(0,18,2):\n",
        "        prob_crr = np.random.random()\n",
        "        if (prob_crr <= 0.9):\n",
        "            point=random.randint(1,6)\n",
        "            mating_pool[kk,:]=mating_pool[select[q],0:point].tolist() + mating_pool[select[q+1],point:].tolist()\n",
        "                                 \n",
        "        else:\n",
        "            p=np.random.randint(n)\n",
        "            prnt_idx=r[p]\n",
        "            r.remove(prnt_idx)\n",
        "            n=n-1\n",
        "            mating_pool[kk,:]=EA_population[prnt_idx,:]\n",
        "                                  \n",
        "    ### MUTATION OPERATOR ###\n",
        "        for zz in range(chromo_size):\n",
        "            if np.random.random() <= 0.12 :                                     #mutation probability is 0.12\n",
        "                mating_pool[kk,zz]=np.random.random()\n",
        "              \n",
        "             \n",
        "        kk=kk+1\n",
        "        if (kk==29):\n",
        "            mating_pool[kk,:]=[mating_pool[19,i] + mating_pool[18,i] for i in range(len(mating_pool[19,:]))] \n",
        "            #mating_pool[kk,:]=mating_pool[19,:]mating_pool[18,:]      # making last mating population as the combi of 19th & 20th mating population\n",
        "        \n",
        "    EA_population=mating_pool\n",
        "    \n",
        "    ## PARAMETER UPDATION\n",
        "    for ff in range(total_fbank): \n",
        "        ## spline1 parameter updation\n",
        "        a1=0.1\n",
        "        yv[ff,1]=EA_population[ff,0]\n",
        "        if yv[ff,1]>=1:\n",
        "            yv[ff,1]=a1+np.random.random()*(1-2*a1)                      # parameter to limit range of spline in bet. 0 & 1   \n",
        "            EA_population[ff,0]=yv[ff,1]\n",
        "                                  \n",
        "        y2_temp=EA_population[ff,0]+EA_population[ff,1]\n",
        "        if (y2_temp >1):\n",
        "            delta_temp=np.random.random()*(1-a-yv[ff,1])\n",
        "            y2_temp=delta_temp+yv[ff,1]\n",
        "            EA_population[ff,1]=delta_temp\n",
        "                                  \n",
        "        yv[ff,2]=y2_temp\n",
        "         \n",
        "        ### spline2 parameter updation\n",
        "        y2_rand[ff,:]=EA_population[ff,4:]\n",
        "        for i in range(4):\n",
        "            if (y2_rand[ff,i]>0.9 or y2_rand[ff,i]<0.25):\n",
        "                y2_rand[ff,i]=np.random.random()*(0.9-0.25)+0.25\n",
        "                EA_population[ff,i+4]=y2_rand[ff,i]\n",
        "          \n",
        "              \n",
        "    \n",
        "    return EA_population,yv,y2_rand\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCIAgX9CRbMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}